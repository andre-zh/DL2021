{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:#0b486b\">  FIT5215: Deep Learning (2021)</span>\n",
    "***\n",
    "*CE/Lecturer:*  **Dr Trung Le** | trunglm@monash.edu <br/>\n",
    "*Head TA:*  **Dr Van Nguyen** | van.nguyen1@monash.edu <br/>\n",
    "*Tutor:* **Mr Anh Bui** \\[tuananh.bui@monash.edu\\] | **Mr Tuan Nguyen**  \\[tuan.ng@monash.edu \\] | **Dr Binh Nguyen** \\[binh.nguyen1@monash.edu\\] | **Dr Mahmoud Mohammad** \\[mahmoud.hossam@monash.edu\\]\n",
    "<br/> <br/>\n",
    "Faculty of Information Technology, Monash University, Australia\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:#0b486b\">Tutorial 1: Deep Learning with TensorFlow</span> #\n",
    "**The purpose of this tutorial is to demonstrate how to work with an open source software library for developing deep neural networks apllications, called TensorFlow (TF). In this tutorial, we present the following topics:**\n",
    "\n",
    "1. A quick tour of TensorFlow 1.x\n",
    "2. How to visualize a computational graph and its node values using Tensorboard.\n",
    "3. Advancements of TensorFlow 2.x in comparison to TensorFlow 1.x.\n",
    "\n",
    "**The tutorial material and code are mainly prepared in TensorFlow 1.x, which involves a low-level programming compared to TensorFlow 2.x to support students in being aware of how TF works and what is under the scene. If students master TF 1.x, it is very convenient and easy to move to TF 2.x. In addition, to facilitate the study of the students, the tutorial content also has additional material to indicate how the TF 1.x code can be ported to that of TF 2.x.** \n",
    "\n",
    "**References and additional reading and resources**\n",
    "- [Installing Tensorflow on Windows](https://www.tensorflow.org/install/install_windows)\n",
    "- [Tensorflow API documentations](https://www.tensorflow.org/versions/master/api_docs/python/)\n",
    "- [Examples with Tensorflow](https://www.tensorflow.org/versions/master/get_started/)\n",
    "\n",
    "**Acknowledgement**: *Some materials used in this tutorial have been adapted from Chapter 3 of the the book \"Learning TensorFlow: A Guide to Building Deep Learning Systems\" by Hope, Resheff and Lieder and Chapter 2 of \"Deep Learning with with TensorFlow 2 and Keras\" by Antonio Culli, Amita Kapoor, Sujit Pal.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#0b486b\"> I. A quick tour of TensorFlow 1.x </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:#0b486b\"> I.1 Computational Graph </span> ###\n",
    "Computational graph is a basic concept of TensorFlow which represents the functional dependency of nodes. The following figure presents a typical computational graph wherein each node is a tensor. <br/>\n",
    "\n",
    "<img src=\"images/ComputationalGraph.png\" width=\"500\" align=\"center\"/> \n",
    "The above computational graph presents some functional dependencies:\n",
    "- $c$ is dependent on $a$, $b$.\n",
    "- $d$ depends on $a$, $e$ depends on $c$.\n",
    "- $f$ depends on $d$, $e$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:#0b486b\"> I.2 Declare a Computational Graph </span>\n",
    "The following code snippet shows how to declare a computational graph in TensorFlow. Once we import TF, a specific `empty default graph` is formed. All the nodes we create are automatically associated with that default graph. It is worth noting that we just `declare a graph` and **nothing** has been executed yet.\n",
    "\n",
    "Below we import TensorFlow 2.x. To ensure that this is comparatible and works with TF 1.x codes, we need to import the coressponding package `tensorflow.compat.v1`.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\kngu0030\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf25-p38\\lib\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = tf.constant(5)\n",
    "b = tf.constant(2)\n",
    "c = tf.constant(3)\n",
    "d = tf.multiply(a,b)\n",
    "e = tf.add(b,c)\n",
    "f = tf.subtract(d,e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<span style=\"color:red\">Exercise 1</span>**: Draw the computational graph of the above computational process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"sol/tut1-e1.png\" width=\"500\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:#0b486b\"> I.3 Fetches Values </span> ###\n",
    "To query the nodes in a computational graph, we create a `session` and run a query in this sesstion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outs=[5, 2, 3, 10, 5, 5]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    fetches = [a,b,c,d,e,f]\n",
    "    outs = sess.run(fetches)\n",
    "    print(\"outs={}\".format(outs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<span style=\"color:red\">Exercise 2</span>**: Write code in the cell below to create a new node $g = a^2 + (b * f)$ and $h= (b+c)*d + e^2*c$, create a session, run a query to compute and display the values of $g$ and $h$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "g=35\n",
      "h=125\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess: \n",
    "    g = a*a + b*f \n",
    "    h = (b+c)*d + e*e*c \n",
    "    print(\"g={}\".format(sess.run(g)))\n",
    "    print(\"h={}\".format(sess.run(h)))\n",
    "    assert(g.eval()==sess.run(g))\n",
    "    assert(h.eval()==sess.run(h))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:#0b486b\"> I.4 More about Graph </span> ###\n",
    "Each TF project is associated with a default computational graph. Besides the default graph, we can create other graphs on demand and work with these graphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "g1= tf.get_default_graph()\n",
    "g2 = tf.Graph()\n",
    "print(g1 is tf.get_default_graph())\n",
    "with g2.as_default():\n",
    "    print(g1 is tf.get_default_graph())\n",
    "    print(g2 is tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:#0b486b\"> I.5 Data Types and Cast </span> ###\n",
    "TensorFlow supports several data types when declaring its nodes. We can cast a node from a data type to another. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x type is <dtype: 'int32'>\n",
      "y type is <dtype: 'float32'>\n"
     ]
    }
   ],
   "source": [
    "x = tf.constant(name=\"x\", value=[1,2,3], dtype= tf.int32)\n",
    "print(\"x type is {}\".format(x.dtype))\n",
    "y = tf.cast(x, tf.float32)\n",
    "print(\"y type is {}\".format(y.dtype))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are the popular data types in TensorFlow.\n",
    "\n",
    "<img src=\"images/TF_DataTypes.png\" width=\"600\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:#0b486b\">I.6 Get Shape </span> ###\n",
    "Each node in a computational graph of TensorFlow is a tensor. We can use the method `get_shape()` to get shape of a tensor. Note that we create an interactive session and use `x.eval()` to evaluate the value of node `x` in the computational graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x= [[[ 1  2  3]\n",
      "  [ 4  5  6]]\n",
      "\n",
      " [[-1 -2 -3]\n",
      "  [-4 -5 -6]]]\n",
      "x shape: (2, 2, 3)\n"
     ]
    }
   ],
   "source": [
    "x= tf.constant([[[1,2,3],[4,5,6]],\n",
    "                [[-1,-2,-3],[-4,-5,-6]]])\n",
    "sess = tf.InteractiveSession()\n",
    "print(\"x= {}\".format(x.eval()))\n",
    "print(\"x shape: {}\".format(x.get_shape()))\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#0b486b\"> I.7 Initialize Tensors </span> ###\n",
    "When declaring nodes in TensorFlow, we can initialize them using a heap of methods offered by TensorFlow. After that we can querry their values in an `interactive session`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "a= tf.constant(name='a', value=3)\n",
    "b= tf.fill(name='b', dims= [2,3], value=-1)\n",
    "c= tf.zeros(name='c', shape= [2,3])\n",
    "d= tf.ones(name='d', shape=[2,3])\n",
    "e= tf.random_normal(name='e', shape=[2,3], mean=0, stddev=1)\n",
    "f= tf.ones_like(e)\n",
    "g= tf.zeros_like(e)\n",
    "h= tf.random_shuffle([5,10,15,20])\n",
    "k= tf.random_uniform([2,3], minval=-1, maxval=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a=3\n",
      "b=[[-1 -1 -1]\n",
      " [-1 -1 -1]]\n",
      "c=[[0. 0. 0.]\n",
      " [0. 0. 0.]]\n",
      "d=[[1. 1. 1.]\n",
      " [1. 1. 1.]]\n",
      "e=[[ 0.3291204   0.68639845 -0.5126701 ]\n",
      " [ 0.64776415  0.23761442 -1.6916677 ]]\n",
      "f=[[1. 1. 1.]\n",
      " [1. 1. 1.]]\n",
      "g=[[0. 0. 0.]\n",
      " [0. 0. 0.]]\n",
      "h=[10  5 20 15]\n",
      "k=[[ 0.25113034  0.37511373  0.90871096]\n",
      " [ 0.12821078 -0.7738824  -0.8114779 ]]\n"
     ]
    }
   ],
   "source": [
    "sess= tf.InteractiveSession()\n",
    "print(\"a={}\".format(a.eval()))\n",
    "print(\"b={}\".format(b.eval()))\n",
    "print(\"c={}\".format(c.eval()))\n",
    "print(\"d={}\".format(d.eval()))\n",
    "print(\"e={}\".format(e.eval()))\n",
    "print(\"f={}\".format(f.eval()))\n",
    "print(\"g={}\".format(g.eval()))\n",
    "print(\"h={}\".format(h.eval()))\n",
    "print(\"k={}\".format(k.eval()))\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:#0b486b\"> I.8 Matrix Multiplication and Activation </span> ###\n",
    "Matrix multiplication in conjunction with activation is a building block in deep learning. In the following code snippet, we declare the matrix $A$ of $(2,3)$ and a vector $x$ of $(3,)$. To be able to apply $A \\times x$, we need to expand $x$ one dimension via the method `tf.expand_dims()`. Now $x$ has shape $(3,1)$ and we can do a matrix multiplication. Finnaly, we apply the activation function ReLu over the output of matrix multiplication: $ReLu(A \\times x)$. In addition, the formulation of ReLu is $ReLu(t)= \\max\\{0,t\\}$, which is the most popular activation function in deep learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A shape: (2, 3)\n",
      "x shape: (3,)\n",
      "x shape: (3, 1)\n",
      "y before activation: [[  6]\n",
      " [-15]]\n",
      "y after activation: [[6]\n",
      " [0]]\n"
     ]
    }
   ],
   "source": [
    "A = tf.constant([[1,2,3],\n",
    "                 [-4,-5,-6]])\n",
    "x= tf.constant([1,1,1])\n",
    "print(\"A shape: {}\".format(A.get_shape()))\n",
    "print(\"x shape: {}\".format(x.get_shape()))\n",
    "x= tf.expand_dims(x,1) # expand one dimension to turn x's shape into (3, 1) \n",
    "print(\"x shape: {}\".format(x.get_shape()))\n",
    "sess= tf.InteractiveSession()\n",
    "y =tf.matmul(A,x)\n",
    "print(\"y before activation: {}\".format(y.eval()))\n",
    "y= tf.nn.relu(y)\n",
    "print(\"y after activation: {}\".format(y.eval()))\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x shape: (3, 1, 1)\n"
     ]
    }
   ],
   "source": [
    "x= tf.expand_dims(x,1)\n",
    "print(\"x shape: {}\".format(x.get_shape()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<span style=\"color:red\">Exercise 3</span>**: Create a tensor $x$ of shape $(3, 1)$ with entry values $x[i, 0]=i$, $\\forall i = 0, 1, 2$ and another tensor $y$ of shape $(1, 3)$ with all entry values of $2$. Create another operation $z$ to perform matrix multiplication of $x$ and $y$. This operation is also called outer product. Print the shape of $z$. Also, run a querry to compute $z$ and print the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 1)\n",
      "(1, 3)\n",
      "[[0 0 0]\n",
      " [2 2 2]\n",
      " [4 4 4]]\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "x = tf.constant([[0],[1],[2]])\n",
    "y = tf.constant([[2,2,2]])\n",
    "z = tf.matmul(x,y)\n",
    "with tf.Session() as sess: \n",
    "    print(x.get_shape())\n",
    "    print(y.get_shape())\n",
    "    print(z.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:#0b486b\">I.9 Name </span> ###\n",
    "Each tensor object also has an identifying name. This name is an *intrinsic* string name. We can use the `object.name` attribute to see the name of the object.\n",
    "Objects residing within the same graph cannot have the same name.\n",
    "\n",
    "\n",
    "TF will automatically add an underscore and a number to distinguish the two which accidentally have the same name. Both objects can have the same name when they are associated with different graphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c1 name: c:0\n",
      "c2 name: c_1:0\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "g = tf.get_default_graph()\n",
    "with g.as_default():\n",
    "    c1= tf.constant(name='c', value=3)\n",
    "    c2= tf.constant(name='c', value=5)\n",
    "print(\"c1 name: {}\".format(c1.name))\n",
    "print(\"c2 name: {}\".format(c2.name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:#0b486b\">I.10 Name Scope </span> ### \n",
    "Name scope is a *hierarchically group nodes* together by name to divide a graph into subgraphs with some semantic meaning. To declare a name space, we use the syntax: `tf.name_scope(\"prefix\")`.\n",
    "\n",
    "Organizing your TensorFlow code using name scopes shows some advantages:\n",
    "- Make it easier to follow and manage.\n",
    "- Visualization of the graph structure.\n",
    "- Useful when dealing with a large, complicated graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c1 name: c_2:0\n",
      "c2 name: prefix/c:0\n",
      "c3 name: prefix/c_1:0\n"
     ]
    }
   ],
   "source": [
    "with tf.get_default_graph().as_default():\n",
    "    c1 = tf.constant(name= \"c\", value=1.0)\n",
    "    with tf.name_scope(\"prefix\"):\n",
    "        c2 = tf.constant(name= \"c\", value=2.0)\n",
    "        c3 = tf.constant(name= \"c\", value=3.0)\n",
    "print(\"c1 name: {}\".format(c1.name))\n",
    "print(\"c2 name: {}\".format(c2.name))\n",
    "print(\"c3 name: {}\".format(c3.name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:#0b486b\">I.11 Variable </span> ### \n",
    "Variable nodes are crucial nodes in a TensorFlow computational graph whose values can be *modified* and *changed*. \n",
    "\n",
    "In a deep learning model, `model parameters` are declared as `variable nodes` in the relevant computational graph whose values are modified during training course. Using variables is done in two stages:\n",
    "- Call the `tf.Variable()` function to create a variable and define what value it will be initialized with.\n",
    "- Explicitly perform an initialization operation by running the session with the `tf.global_variables_initializer()` method. This will allocate the memory for the variable and set its initial values.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-run my_var: <tf.Variable 'x:0' shape=(2, 3) dtype=float32_ref>\n",
      "Post-run my_var: [[-0.11726787 -0.07957689  0.08123686]\n",
      " [ 0.01206291 -0.17473172  0.08374216]]\n"
     ]
    }
   ],
   "source": [
    "init_var = tf.random.normal(shape=[2,3], mean=0, stddev=0.1, dtype= tf.float32)\n",
    "my_var=  tf.Variable(initial_value= init_var, name='x')\n",
    "init= tf.global_variables_initializer()\n",
    "print(\"Pre-run my_var: {}\".format(my_var))\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    my_var = sess.run(my_var)\n",
    "    print(\"Post-run my_var: {}\".format(my_var))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below presents some popular ways to *randomly initialize* the intial values of variables.\n",
    "\n",
    "<img src=\"images/tf_random.png\" width=\"800\" align=\"center\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:#0b486b\">I.12 Variable Scope and Reuse Variable </span> ###  \n",
    "\n",
    "Sometimes we might want to reuse a variable. This can be done by `tf.get_variable()`, which either reuses the variable with a specified name or creates a new variable with the name if it is not created before.\n",
    "\n",
    "If we want to reuse a variable later, we first need to declare this in a variable scope with `tf.variable_scope()` and then in this variable scope invoke `tf.get_variable()` with the flag reuse to be set to `True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W1 and W2 are tight\n"
     ]
    }
   ],
   "source": [
    "with tf.variable_scope(\"layer1\"):\n",
    "    W1= tf.get_variable(name='W', shape=[2,3], dtype= tf.float32, initializer= tf.initializers.random_normal(0,0.1))\n",
    "    x= tf.Variable(initial_value=tf.random_normal([4,2], 0, 0.1), name=\"x\")\n",
    "    v1= tf.matmul(x, W1)\n",
    "\n",
    "with tf.variable_scope(\"layer1\", reuse=True):\n",
    "    W2= tf.get_variable(name='W', shape=[2,3], dtype= tf.float32, initializer= tf.initializers.random_normal(0,0.2))\n",
    "\n",
    "diff = tf.subtract(W1,W2)\n",
    "norm_diff = tf.norm(diff, ord='euclidean')\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    norm_diff= sess.run(norm_diff)\n",
    "\n",
    "if norm_diff==0:\n",
    "    print(\"W1 and W2 are tight\")\n",
    "else:\n",
    "    print(\"W1 and W2 are not tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:#0b486b\">I.13 Name Scope & Variable Scope </span> ###   \n",
    "There are two different types of scopes: `name scope` created using `tf.name_scope` and `variable scope` created using `tf.variable_scope`. Both scopes have the same effect on all operations as well as variables created using `tf.Variable`, while only variable scope affects on `tf.get_variable()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following figure shows the difference of two ways to create variables: `tf.Variable` and `tf.get_variable()`. <br/>\n",
    "\n",
    "<img src=\"images/Compare2WaysVariables.png\" width=\"400\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c1 name: ns/vs/c:0\n",
      "c2 name: vs/c:0\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "with tf.name_scope(\"ns\"):\n",
    "    with tf.variable_scope(\"vs\", reuse=tf.AUTO_REUSE):\n",
    "        c1= tf.Variable(name=\"c\", initial_value= tf.constant(1.0))\n",
    "        c2= tf.get_variable(name=\"c\", initializer= tf.constant([-1,1]))\n",
    "print(\"c1 name: {}\".format(c1.name))\n",
    "print(\"c2 name: {}\".format(c2.name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<span style=\"color:red\">Exercise 4</span>**: TensorFlow can also automatically decide to create a new variable if it does not exist and reuse if it is already created by setting `reuse=tf.AUTO_REUSE` as shown in the function `linear()` below. Questions:\n",
    "\n",
    "(a) What is the value of `diff`? You can run a session to compute its value to answer this question.\n",
    "\n",
    "(b) Why does `diff` get that value?\n",
    "\n",
    "(c) What happens if we set `reuse=False` in the delaration of `z` in the code below? Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "[[-0.]\n",
      " [-0.]\n",
      " [-0.]]\n",
      "Const\n",
      "linear/weights/Initializer/random_uniform/shape\n",
      "linear/weights/Initializer/random_uniform/min\n",
      "linear/weights/Initializer/random_uniform/max\n",
      "linear/weights/Initializer/random_uniform/RandomUniform\n",
      "linear/weights/Initializer/random_uniform/sub\n",
      "linear/weights/Initializer/random_uniform/mul\n",
      "linear/weights/Initializer/random_uniform\n",
      "linear/weights\n",
      "linear/weights/Assign\n",
      "linear/weights/read\n",
      "linear/MatMul\n",
      "linear_1/MatMul\n",
      "sub\n",
      "init\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "def linear(x, output_dim, reuse=tf.AUTO_REUSE):\n",
    "    with tf.variable_scope(\"linear\", reuse=reuse):\n",
    "        W = tf.get_variable('weights', shape=[output_dim, x.get_shape()[0]], dtype=tf.float32)\n",
    "        output = tf.matmul(W, x)\n",
    "        return output\n",
    "    \n",
    "x = tf.constant(0.0, shape=(3, 1))\n",
    "y = linear(x, 3, reuse=tf.AUTO_REUSE)\n",
    "z = linear(x, 3, reuse=tf.AUTO_REUSE)\n",
    "diff = y - z\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess: \n",
    "    sess.run(init)\n",
    "    print('x={}'.format(sess.run(x)))\n",
    "    print('diff={}'.format(sess.run(diff)))\n",
    "\n",
    "# To get the names of all tensor in the default graph \n",
    "# for op in tf.get_default_graph().get_operations():\n",
    "#     print(str(op.name))\n",
    "    \n",
    "# To get all variables\n",
    "# for var in tf.global_variables(): \n",
    "#     print(var.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Write your answer here:**\n",
    "\n",
    "(a)\n",
    "\n",
    "(b)\n",
    "\n",
    "(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:#0b486b\">I.14 Place Holder </span> ###    \n",
    "Placeholders can be thought of as `empty variables` that will be filled with data later on.\n",
    "\n",
    "We use them when constructing our graph and when executing querying value of nodes, we need to feed them with the input data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s= 0.06081658601760864\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "tf.reset_default_graph()\n",
    "x_data= np.random.rand(10,3)\n",
    "\n",
    "with tf.name_scope(\"layer1\"):\n",
    "    W = tf.Variable(name= \"W\", initial_value=tf.random.normal([1,10],0,0.1, dtype= tf.float32))\n",
    "    b = tf.Variable(name=\"b\", initial_value=tf.random.normal([1,3],0,0.1, dtype=tf.float32))\n",
    "    x = tf.placeholder(name=\"x\", shape=[10,3], dtype= tf.float32)\n",
    "    v = tf.matmul(W,x) + b\n",
    "    s = tf.reduce_mean(v)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    s= sess.run(s, feed_dict={x:x_data})\n",
    "\n",
    "print(\"s= {}\".format(s))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### <span style=\"color:#0b486b\">I.16 Save and Restore Model </span> ###   \n",
    " It is very convenient to save a model to hard disk and then restore that model in TensorFlow as shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved in path: ./models/tmp/model.ckpt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Create some variables.\n",
    "v1 = tf.get_variable(\"v1\", shape=[3], initializer = tf.zeros_initializer)\n",
    "v2 = tf.get_variable(\"v2\", shape=[5], initializer = tf.zeros_initializer)\n",
    "\n",
    "inc_v1 = v1.assign(v1+1)\n",
    "dec_v2 = v2.assign(v2-1)\n",
    "\n",
    "# Add an op to initialize the variables.\n",
    "init_op = tf.global_variables_initializer()\n",
    "\n",
    "# Add ops to save and restore all the variables.\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "# Later, launch the model, initialize the variables, do some work, and save the\n",
    "# variables to disk.\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init_op)\n",
    "    # Do some work with the model.\n",
    "    inc_v1.op.run()\n",
    "    dec_v2.op.run()\n",
    "    if not os.path.exists(os.path.abspath(\"./models/tmp\")):\n",
    "        os.makedirs(os.path.abspath(\"./models/tmp\"))\n",
    "    # Save the variables to disk.\n",
    "    save_path = saver.save(sess, \"./models/tmp/model.ckpt\")\n",
    "    print(\"Model saved in path: %s\" % save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./models/tmp/model.ckpt\n",
      "Model restored.\n",
      "v1 : [1. 1. 1.]\n",
      "v2 : [-1. -1. -1. -1. -1.]\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "# Create some variables.\n",
    "v1 = tf.get_variable(\"v1\", shape=[3])\n",
    "v2 = tf.get_variable(\"v2\", shape=[5])\n",
    "\n",
    "# Add ops to save and restore all the variables.\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "# Later, launch the model, use the saver to restore variables from disk, and\n",
    "# do some work with the model.\n",
    "with tf.Session() as sess:\n",
    "    # Restore variables from disk.\n",
    "    saver.restore(sess, \"./models/tmp/model.ckpt\")\n",
    "    print(\"Model restored.\")\n",
    "    # Check the values of the variables\n",
    "    print(\"v1 : %s\" % v1.eval())\n",
    "    print(\"v2 : %s\" % v2.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:#0b486b\">I.17. Visualization with TensorBoard</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <span style=\"color:#0b486b\"> Logging and creating summary for visualization </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usually one would use the `print()` function and `matplotlib` to visualize progress during training. There is a better way to do this via TensorBoard. If you feed in training stats, it will display nice interactive visualizations of\n",
    "these stats in your web browser (e.g., learning curves).\n",
    "\n",
    "You can also provide the graph’s definition and TensorBoard provides interface to browse through it. This is very useful to identify errors in the graph, to find bottlenecks, and so on.\n",
    "\n",
    "Let's visualize learning rate and global step in the example above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construction\n",
    "tf.reset_default_graph()\n",
    "\n",
    "starter_lr = 1.\n",
    "decay_rate = 0.9\n",
    "global_step = tf.Variable(0., trainable=0)\n",
    "incr = tf.assign(global_step, global_step + 1)\n",
    "\n",
    "with tf.control_dependencies([incr]):\n",
    "    learning_rate = starter_lr * tf.pow(decay_rate, global_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we construct the graph as normal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.summary.scalar('learning_rate', learning_rate)\n",
    "tf.summary.scalar('global_step', global_step)\n",
    "merged = tf.summary.merge_all() # Merges all summaries collected in the default graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first two lines create two summary ops in the graph that will evaluate the learning_rate and global_step value and write them to a TensorBoard compatible binary log string called a summary.\n",
    "\n",
    "The third line creates a node that merges all summaries collected in the default graph. In the execution phase, you'll need to evaluate the merged node regularly during training (e.g., every 10 mini-batches). This will output a summary that you can then write to the events file using the *`file_writer`*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "logdir = \"tf_logs/example01/model-at-{}\".format(time.strftime('%Y-%m-%d_%H.%M.%S'))\n",
    "file_writer = tf.summary.FileWriter(logdir, tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/note.gif\" width=\"40\" align=\"left\"> Tip: You need to use a different log directory every time you run your program, or else TensorBoard will merge stats from different runs, which will mess up the visualizations. The simplest solution for this is to include a timestamp in the log directory name."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now's the execution phase: <br>\n",
    "\\- The first line creates a node in the graph that will evaluate the *MSE* value and write it to a TensorBoard compatible binary log string called a summary. Then you need to update the execution phase to evaluate the *`mse_summary`* node regularly during training\n",
    "(e.g., every 10 mini-batches). This will output a summary that you can then write to the events file using\n",
    "the *`file_writer`*. Here is the updated code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    global_step.initializer.run()\n",
    "    for i in range(50):\n",
    "        merged_ = merged.eval()\n",
    "        file_writer.add_summary(merged_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/warning.png\" width=\"40\" align=\"left\"></img> **Warning**: *In real-world application logging training stats at every single training step would significantly slow down training; instead, one should log at regular interval, such as after each 200 iterations*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, you want to close the FileWriter at the end of the program:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <span style=\"color:#0b486b\"> Using TensorBoard server to visualize </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! Now it’s time to fire up the TensorBoard server. You need to activate your virtual environment\n",
    "if you created one, then start the server by running the *`tensorboard`* command, pointing it to the root log\n",
    "directory. This starts the TensorBoard web server, listening on port 6006 <br> <br>\n",
    "- Open command line, nevigate to the folder of this tute and run **> tensorboard --logdir tf_logs**\n",
    "- Open your browser and go to https://localhost:6006. Welcome to\n",
    "TensorBoard! In the Scalars tab, you'll see *`global_step`* and *`learning_rate`*: <br><br>\n",
    "\n",
    "<img src='images/learning_rate.png' width=300>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#0b486b\"> II. Understanding TensorFlow 2.x </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:#0b486b\"> II.1. Advancements of TensorFlow 2.x </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In TF 1.x, we need to declare a computational graph manually and create session to query node values. This is different from an imperative and high-level programing language such as Python, which is much easier to work with and more dynamic. TF 2.x brings TF to closer to an imperative and high-level programming language such as Python, thereby making the task of building up deep learning models more conveniently. This is due to two new features: **eager execution** and **AutoGraph**.\n",
    "- **Eager execution**: you still have a graph, but you can define, change, and execute nodes on-the-ﬂy, with no special session interfaces or placeholders. This is what is called eager execution, meaning that the model definitions are dynamic, and the execution is immediate. Graphs and sessions should be considered as implementation details. In TF 2.x, we do not need to work directly with a computational graph and session.\n",
    "- **AutoGraph**: AutoGraph takes eager-style Python code and automatically converts it to graph-generating code. So, again, transparently TensorFlow 2.x creates a bridge between imperative, dynamic, and eager Python style programming with efficient graph computations, taking the best of both worlds.\n",
    "\n",
    "In addition, Keras has been incorporated in and become a part of TF 2.x, which allows us to build up deep learning models comfortably and conveniently.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:#0b486b\"> II.2. TensorFlow 2.x's API and architecture</span>\n",
    "\n",
    "The below image shows the API of TF 2.x. At the lowest level, each TensorFlow operation (op for short) is implemented using highly efficient C++ code. Many operations have multiple implementations called kernels: each kernel is dedicated to a specific device type, such as CPUs, GPUs, or even TPUs (tensor processing units).\n",
    "\n",
    "<img src='images/TF_API.png' align=center width=600>\n",
    "\n",
    "\n",
    "The architecture of TF 2.x is shown in the following image. Most of the time your code will use the high-level APIs (especially tf.keras and tf.data); but when you need more flexibility, you will use the lower-level Python API, handling tensors directly. \n",
    "\n",
    "<img src='images/TF_Architecture.png' align=center width=600>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:#0b486b\"> II.3. Using TensorFlow like NumPy</span>\n",
    "\n",
    "#### <span style=\"color:#0b486b\"> Tensors and Operations </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "t= tf.constant([[1,2,3],[4,5,6]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 3)\n",
      "<dtype: 'int32'>\n"
     ]
    }
   ],
   "source": [
    "print(t.shape)\n",
    "print(t.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       "array([[2, 3],\n",
       "       [5, 6]])>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=int32, numpy=\n",
       "array([[11, 12, 13],\n",
       "       [14, 15, 16]])>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t + 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=int32, numpy=\n",
       "array([[ 1,  4,  9],\n",
       "       [16, 25, 36]])>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.square(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[1 2 3]\n",
      " [4 5 6]], shape=(2, 3), dtype=int32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=int32, numpy=array([5, 7, 9])>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(t)\n",
    "tf.reduce_sum(t, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
       "array([[1, 4],\n",
       "       [2, 5],\n",
       "       [3, 6]])>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.transpose(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will find all the basic math operations you need (`tf.add(), tf.multiply(), tf.square(), tf.exp(), tf.sqrt()`, etc.) and most operations that you can find in NumPy (e.g., `tf.reshape(), tf.squeeze(), tf.tile()`). Some functions have a dif‐ ferent name than in NumPy; for instance, `tf.reduce_mean(), tf.reduce_sum(), tf.reduce_max(), and tf.math.log()` are the equivalent of `np.mean(), np.sum(), np.max() and np.log()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:#0b486b\"> Variable</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(2, 3) dtype=float32, numpy=\n",
       "array([[1., 1., 1.],\n",
       "       [1., 1., 1.]], dtype=float32)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = tf.Variable(tf.ones([2,3], dtype= tf.float32))\n",
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(2, 3) dtype=float32, numpy=\n",
       "array([[2., 2., 2.],\n",
       "       [2., 2., 2.]], dtype=float32)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.assign(2*v)\n",
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(2, 3) dtype=float32, numpy=\n",
       "array([[ 2., 10.,  2.],\n",
       "       [ 2.,  2., 20.]], dtype=float32)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v[0,1].assign(10)\n",
    "v[1,2].assign(20)\n",
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(2, 3) dtype=float32, numpy=\n",
       "array([[100.,  10.,   2.],\n",
       "       [  2.,   2., 200.]], dtype=float32)>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.scatter_nd_update(indices=[[0, 0], [1, 2]], updates=[100., 200.])\n",
    "v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:#0b486b\"> TF Functions and Graph</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cube(x):\n",
    "    return x**3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cube(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=8>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cube(tf.constant(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.eager.def_function.Function at 0x254bcc2cd60>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_cube = tf.function(cube)\n",
    "tf_cube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=8>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_cube(tf.constant(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def tf_cube(x):\n",
    "    return x**3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.eager.def_function.Function at 0x254bcc99730>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_cube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_cube.python_function(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:#0b486b\"> AutoGraph and Tracing</span>\n",
    "To fulfill the autograph feature, TF 2.x need to parse and analyze Python functions to capture all the control flow statements, such as *for loops, while loops*, and *if* statements, as well as *break, continue*, and *return statements*. \n",
    "\n",
    "After analyzing the function’s code, AutoGraph outputs an upgraded version of that function in which all the control flow statements are replaced by the appropriate TensorFlow operations, such as `tf.while_loop()` ,`for loops`, and `tf.cond()` for if statements. \n",
    "\n",
    "In the below figure, the function `sum_square(n)` is analyzed and transformed to the function `tf_sum_square(n)`, which is more convenient to be executed in the graph mode in the next step. When you invoke the former function: `sum_square(tf.constant(5))` for example, the upgraded function `tf__sum_squares()` function will be called with a symbolic tensor of type int32 and shape []. The function will run in graph mode, meaning that each TensorFlow operation will add a node in the graph to represent itself and its output tensor(s) (as opposed to the regular mode, called eager execution, or eager mode). In the following figure, you can see the `tf__sum_squares()` function being called with a symbolic tensor as its argument (in this case, an int32 tensor of shape []) and the final graph being generated during tracing. \n",
    "\n",
    "<img src='images/AutoGraph.png' align=center width=700>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### <span style=\"color:#0b486b\"> <div  style=\"text-align:center\">**THE END**</div> </span>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
