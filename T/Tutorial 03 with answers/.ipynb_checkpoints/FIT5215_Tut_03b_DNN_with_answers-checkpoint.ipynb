{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:#0b486b\">  FIT5215: Deep Learning (2021)</span>\n",
    "***\n",
    "*CE/Lecturer:*  **Dr Trung Le** | trunglm@monash.edu <br/>\n",
    "*Head TA:*  **Dr Van Nguyen** | van.nguyen1@monash.edu <br/>\n",
    "*Tutor:* **Mr Anh Bui** \\[tuananh.bui@monash.edu\\] | **Mr Tuan Nguyen**  \\[tuan.ng@monash.edu \\] | **Dr Binh Nguyen** \\[binh.nguyen1@monash.edu\\] | **Dr Mahmoud Mohammad** \\[mahmoud.hossam@monash.edu\\]\n",
    "<br/> <br/>\n",
    "Faculty of Information Technology, Monash University, Australia\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:#0b486b\">Tutorial 3b: Feed-forward Neural Nets with TensorFlow 2.x</span>\n",
    "**This continues Tutorial 2a and shows you how to implement a feedforward neural network using TF 2.x**:  \n",
    "- ***Inspect how to use keras in TF 2.x to fulfill the task. As you can see later the implementation is much simpler*.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:#0b486b\"> II.1 Feedforward Neural Network </span> <span style=\"color:red\">***** (highly important)</span>\n",
    "#### <span style=\"color:#0b486b\"> Tutorial objective </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, we will consider a fairly realistic deep NN with *three* layers plus the *output* layer. Its architecture will be specified as $16 \\rightarrow 10 (ReLU) \\rightarrow 20 (ReLU) \\rightarrow 15 (ReLU) \\rightarrow 26$. This means:\n",
    "- The input size is 16\n",
    "- The first layer has 10 hidden units with 10 ReLU activation functions\n",
    "- The second layer has 20 hidden units with 20 ReLU activation functions\n",
    "- The third layer has 15 hidden units with 15 ReLU activation functions\n",
    "- And the output layer is a logit layer with 26 hidden units"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This network, for example, can take the `letter` dataset input with $16$ features and with $26$ classes (A-Z). **Our objective in this tutorial is to implement this specific network in `TensorFlow 1.x`.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:#0b486b\"> II.2 Implementation with TensorFlow 2.x</span> <span style=\"color:red\">***** (highly important)</span>\n",
    "We now shall implement the aforementioned network with the architecture of $16 \\rightarrow 10 (ReLU) \\rightarrow 20 (ReLU) \\rightarrow 15 (ReLu) \\rightarrow 26$ in Tensorflow using the dataset `letter`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This letter dataset can be found at [the LIBSVM website](https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/multiclass.html#letter). Here is the dataset information:\n",
    "-  *The objective is to identify each of a large number of black-and-white rectangular pixel displays as one of the 26 capital letters in the English alphabet. The character images were based on 20 different fonts and each letter within these 20 fonts was randomly distorted to produce a file of 20,000 unique stimuli. Each stimulus was converted into 16 primitive numerical attributes (statistical moments and edge counts) which were then scaled to fit into a range of integer values from 0 through 15*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A typical pipeline process of implementing a deep learning model is as follows:\n",
    "\n",
    "1. **Data processing**: \n",
    "    - Load the dataset and split it into train, valid, and test sets.  \n",
    "     \n",
    "2. **Building the model**: \n",
    "    - Build the model using keras layers.\n",
    "     \n",
    "3. **Compiling the model**: \n",
    "    - Compile the model and specify the optimizer, the loss (e.g., cross-entropy loss) you want to optimize, metrics you want to measure. \n",
    "    \n",
    "4. **Training and evaluating**:\n",
    "    - Train the model with a specific training set and validation set in a number of epochs.\n",
    "    - Predict the test set and assess its performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:#0b486b\">1. Data Processing </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use `sklearn` to load the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_svmlight_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X data shape: (15000, 16)\n",
      "y data shape: (15000,)\n",
      "# classes: 26\n",
      "[ 1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12. 13. 14. 15. 16. 17. 18.\n",
      " 19. 20. 21. 22. 23. 24. 25. 26.]\n"
     ]
    }
   ],
   "source": [
    "data_file_name= \"letter_scale.libsvm\"\n",
    "data_file = os.path.abspath(\"./data/\" + data_file_name)\n",
    "X_data, y_data = load_svmlight_file(data_file)\n",
    "X_data= X_data.toarray()\n",
    "print(\"X data shape: {}\".format(X_data.shape))\n",
    "print(\"y data shape: {}\".format(y_data.shape))\n",
    "print(\"# classes: {}\".format(len(np.unique(y_data))))\n",
    "print(np.unique(y_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use `sklearn` to split the dataset into the train, validation, and test sets. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "\n",
    "def train_valid_test_split(data, target, train_size, test_size):\n",
    "    valid_size = 1 - (train_size + test_size)\n",
    "    X1, X_test, y1, y_test = train_test_split(data, target, test_size = test_size, random_state= 33)\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(X1, y1, test_size = float(valid_size)/(valid_size+ train_size))\n",
    "    return X_train, X_valid, X_test, y_train, y_valid, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we would like to encode the label in the form of numeric vector. For example, we want to turn $y\\_data=[\"cat\", \"dog\", \"cat\", \"lion\", \"dog\"]$ to $y\\_data=[0,1,0,2,1]$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do this, in the following segment of code, we use the object `le` as an instance of the class `preprocessing.LabelEncoder()` which supports us to transform categorical labels in `y_data` to a numerical vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[25 15 18 ...  0 11 21]\n"
     ]
    }
   ],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(y_data.ravel())\n",
    "y_data= le.transform(y_data)\n",
    "print(y_data[:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now use the function defined above to prepare our data for training, validating and testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12000, 16) (1500, 16) (1500, 16)\n",
      "(12000,) (1500,) (1500,)\n",
      "lables: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25]\n"
     ]
    }
   ],
   "source": [
    "X_train, X_valid, X_test, y_train, y_valid, y_test = train_valid_test_split(X_data, y_data, train_size=0.8, test_size=0.1)\n",
    "y_train= y_train.reshape(-1)\n",
    "y_test= y_test.reshape(-1)\n",
    "y_valid= y_valid.reshape(-1)\n",
    "print(X_train.shape, X_valid.shape, X_test.shape)\n",
    "print(y_train.shape, y_valid.shape, y_test.shape)\n",
    "print(\"lables: {}\".format(np.unique(y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size= int(X_train.shape[0])\n",
    "n_features= int(X_train.shape[1])\n",
    "n_classes= len(np.unique(y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:#0b486b\">2. Build up the model </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We build up a feedforward neural network with the architecture: $16 \\rightarrow 10 (ReLU) \\rightarrow 20 (ReLU) \\rightarrow 15 (ReLu) \\rightarrow 26$ in TensorFlow 2.x."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnn_model = Sequential()\n",
    "dnn_model.add(Dense(units=10,  input_shape=(16,), activation='relu'))\n",
    "dnn_model.add(Dense(units=20, activation='relu'))\n",
    "dnn_model.add(Dense(units=15, activation='relu'))\n",
    "dnn_model.add(Dense(units=n_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 10)                170       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 20)                220       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 15)                315       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 26)                416       \n",
      "=================================================================\n",
      "Total params: 1,121\n",
      "Trainable params: 1,121\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "dnn_model.build()  # computional graph\n",
    "dnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.keras.layers.core.Dense at 0x24b0bdcf280>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x24b0bdcf640>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x24b12dc7550>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x24b12f25100>]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnn_model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dense\n"
     ]
    }
   ],
   "source": [
    "hidden1 = dnn_model.layers[0]\n",
    "print(hidden1.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_init = dnn_model.get_weights()\n",
    "weights, biases = hidden1.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 10)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10,)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biases.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:#0b486b\">3. Compiling Model </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnn_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:#0b486b\">4. Training and Evaluating </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "375/375 [==============================] - 1s 907us/step - loss: 2.9404 - accuracy: 0.1262 - val_loss: 2.2729 - val_accuracy: 0.3247\n",
      "Epoch 2/20\n",
      "375/375 [==============================] - 0s 643us/step - loss: 1.8908 - accuracy: 0.4113 - val_loss: 1.7285 - val_accuracy: 0.4653\n",
      "Epoch 3/20\n",
      "375/375 [==============================] - 0s 632us/step - loss: 1.6079 - accuracy: 0.5067 - val_loss: 1.5617 - val_accuracy: 0.5367\n",
      "Epoch 4/20\n",
      "375/375 [==============================] - 0s 632us/step - loss: 1.4684 - accuracy: 0.5633 - val_loss: 1.4562 - val_accuracy: 0.5707\n",
      "Epoch 5/20\n",
      "375/375 [==============================] - 0s 649us/step - loss: 1.3768 - accuracy: 0.5936 - val_loss: 1.3759 - val_accuracy: 0.5867\n",
      "Epoch 6/20\n",
      "375/375 [==============================] - 0s 653us/step - loss: 1.3061 - accuracy: 0.6137 - val_loss: 1.3088 - val_accuracy: 0.6173\n",
      "Epoch 7/20\n",
      "375/375 [==============================] - 0s 674us/step - loss: 1.2453 - accuracy: 0.6270 - val_loss: 1.2581 - val_accuracy: 0.6187\n",
      "Epoch 8/20\n",
      "375/375 [==============================] - 0s 643us/step - loss: 1.1907 - accuracy: 0.6414 - val_loss: 1.2041 - val_accuracy: 0.6327\n",
      "Epoch 9/20\n",
      "375/375 [==============================] - 0s 659us/step - loss: 1.1412 - accuracy: 0.6590 - val_loss: 1.1619 - val_accuracy: 0.6487\n",
      "Epoch 10/20\n",
      "375/375 [==============================] - 0s 668us/step - loss: 1.0970 - accuracy: 0.6697 - val_loss: 1.1235 - val_accuracy: 0.6493\n",
      "Epoch 11/20\n",
      "375/375 [==============================] - 0s 681us/step - loss: 1.0574 - accuracy: 0.6802 - val_loss: 1.0844 - val_accuracy: 0.6820\n",
      "Epoch 12/20\n",
      "375/375 [==============================] - 0s 649us/step - loss: 1.0203 - accuracy: 0.6933 - val_loss: 1.0418 - val_accuracy: 0.7053\n",
      "Epoch 13/20\n",
      "375/375 [==============================] - 0s 669us/step - loss: 0.9910 - accuracy: 0.7047 - val_loss: 1.0084 - val_accuracy: 0.7080\n",
      "Epoch 14/20\n",
      "375/375 [==============================] - 0s 701us/step - loss: 0.9602 - accuracy: 0.7135 - val_loss: 0.9885 - val_accuracy: 0.7187\n",
      "Epoch 15/20\n",
      "375/375 [==============================] - 0s 622us/step - loss: 0.9381 - accuracy: 0.7229 - val_loss: 0.9686 - val_accuracy: 0.7147\n",
      "Epoch 16/20\n",
      "375/375 [==============================] - 0s 691us/step - loss: 0.9159 - accuracy: 0.7302 - val_loss: 0.9489 - val_accuracy: 0.7300\n",
      "Epoch 17/20\n",
      "375/375 [==============================] - 0s 654us/step - loss: 0.8984 - accuracy: 0.7337 - val_loss: 0.9268 - val_accuracy: 0.7427\n",
      "Epoch 18/20\n",
      "375/375 [==============================] - 0s 644us/step - loss: 0.8846 - accuracy: 0.7398 - val_loss: 0.9176 - val_accuracy: 0.7387\n",
      "Epoch 19/20\n",
      "375/375 [==============================] - 0s 664us/step - loss: 0.8703 - accuracy: 0.7429 - val_loss: 0.8929 - val_accuracy: 0.7440\n",
      "Epoch 20/20\n",
      "375/375 [==============================] - 0s 696us/step - loss: 0.8569 - accuracy: 0.7467 - val_loss: 0.8870 - val_accuracy: 0.7393\n"
     ]
    }
   ],
   "source": [
    "history = dnn_model.fit(x=X_train, y=y_train, batch_size=32, epochs=20, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now can evaluate the trained model on the test set or any subset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47/47 [==============================] - 0s 563us/step - loss: 0.8889 - accuracy: 0.7300\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.8888612389564514, 0.7300000190734863]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnn_model.evaluate(X_test, y_test)  #return loss and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.  , 0.  , 0.  , 0.24, 0.  , 0.05, 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "       0.  , 0.  , 0.  , 0.  , 0.7 , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "       0.  , 0.  , 0.  , 0.  ], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new = X_test[:10]\n",
    "y_prob = dnn_model.predict(X_new)\n",
    "y_prob[0].round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Incorrect prediction!\n",
      "Corrected predeiction!\n",
      "Incorrect prediction!\n",
      "Incorrect prediction!\n",
      "Corrected predeiction!\n",
      "Corrected predeiction!\n",
      "Corrected predeiction!\n",
      "Corrected predeiction!\n",
      "Corrected predeiction!\n",
      "Corrected predeiction!\n"
     ]
    }
   ],
   "source": [
    "y_pred = np.argmax(dnn_model.predict(X_new), axis=-1)\n",
    "for i in range(X_new.shape[0]):\n",
    "    if y_pred[i]==y_test[i]:\n",
    "        print(\"Corrected predeiction!\")\n",
    "    else:\n",
    "        print(\"Incorrect prediction!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:#0b486b\">5. Visualizing the Performance and Loss Objective Function </span>\n",
    "\n",
    "The `fit()` method returns a History object containing the training parameters (history.params), the list of epochs it went through (history.epoch), and most importantly a dictionary (history.history) containing the loss and extra metrics it measured at the end of each epoch on the training set and on the validation set (if any). If you use this dictionary to create a pandas DataFrame and call its plot() method, you get the learning curves shown in the following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1) # set the vertical range to [0-1]\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:#0b486b\">6. Playing around with different optimizers</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*Evaluating with Nadam\n",
      "\n",
      "47/47 [==============================] - 0s 499us/step - loss: 0.8163 - accuracy: 0.7527\n",
      "The test accuracy is 0.7526666522026062\n",
      "\n",
      "*Evaluating with Adam\n",
      "\n",
      "47/47 [==============================] - 0s 471us/step - loss: 0.7707 - accuracy: 0.7760\n",
      "The test accuracy is 0.7760000228881836\n",
      "\n",
      "*Evaluating with Adadelta\n",
      "\n",
      "47/47 [==============================] - 0s 363us/step - loss: 3.2525 - accuracy: 0.0487\n",
      "The test accuracy is 0.04866666719317436\n",
      "\n",
      "*Evaluating with Adagrad\n",
      "\n",
      "47/47 [==============================] - 0s 671us/step - loss: 3.1262 - accuracy: 0.0813\n",
      "The test accuracy is 0.08133333176374435\n",
      "\n",
      "*Evaluating with RMSprop\n",
      "\n",
      "47/47 [==============================] - 0s 520us/step - loss: 0.8285 - accuracy: 0.7467\n",
      "The test accuracy is 0.746666669845581\n",
      "\n",
      "*Evaluating with SGD\n",
      "\n",
      "47/47 [==============================] - 0s 520us/step - loss: 3.1807 - accuracy: 0.0880\n",
      "The test accuracy is 0.08799999952316284\n",
      "\n",
      "The best accuracy is 0.7760000228881836 with Adam\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "optimizer_names = [\"Nadam\", \"Adam\", \"Adadelta\", \"Adagrad\", \"RMSprop\", \"SGD\"]\n",
    "optimizer_list = [keras.optimizers.Nadam(learning_rate=0.001), keras.optimizers.Adam(learning_rate=0.001), keras.optimizers.Adadelta(learning_rate=0.001), \n",
    "                  keras.optimizers.Adagrad(learning_rate=0.001), keras.optimizers.RMSprop(learning_rate=0.001), keras.optimizers.SGD(learning_rate=0.001)]\n",
    "best_acc = 0\n",
    "best_i = -1\n",
    "for i in range(len(optimizer_list)):\n",
    "    dnn_model.set_weights(model_init)\n",
    "    print(\"*Evaluating with {}\\n\".format(str(optimizer_names[i])))\n",
    "    dnn_model.compile(optimizer=optimizer_list[i], loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    dnn_model.fit(x=X_train, y=y_train, batch_size=32, epochs=30, validation_data=(X_valid, y_valid), verbose=0)\n",
    "    acc = dnn_model.evaluate(X_test, y_test)[1]\n",
    "    print(\"The test accuracy is {}\\n\".format(acc))\n",
    "    if acc > best_acc:\n",
    "        best_acc = acc\n",
    "        best_i = i\n",
    "print(\"The best accuracy is {} with {}\".format(best_acc, optimizer_names[best_i]))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:#0b486b\"> II.3 Other Approaches to Build Up Models with TensorFlow 2.x</span> <span style=\"color:red\">*** (relatively important)</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:#0b486b\"> 1. Approach 1: Declaring a class inherited from `tf.keras.Model`</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDNN(tf.keras.Model):\n",
    "    def __init__(self, n_classes= 26):\n",
    "        super(MyDNN, self).__init__()\n",
    "        self.n_classes = n_classes\n",
    "        self.dense1 = tf.keras.layers.Dense(units=10, activation= 'relu')\n",
    "        self.dense2 = tf.keras.layers.Dense(units=20, activation= 'relu')\n",
    "        self.dense3 = tf.keras.layers.Dense(units=15, activation= 'relu')\n",
    "        self.dense4 = tf.keras.layers.Dense(units=self.n_classes, activation= 'softmax')\n",
    "    \n",
    "    def call(self,X): #X is the input, method call specifies how to compute the output from the input X\n",
    "        h = self.dense1(X)\n",
    "        h = self.dense2(h)\n",
    "        h = self.dense3(h)\n",
    "        h = self.dense4(h)\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "188/188 [==============================] - 0s 1ms/step - loss: 3.1689 - accuracy: 0.0828 - val_loss: 2.8698 - val_accuracy: 0.1507\n",
      "Epoch 2/20\n",
      "188/188 [==============================] - 0s 704us/step - loss: 2.4778 - accuracy: 0.2648 - val_loss: 2.1183 - val_accuracy: 0.3647\n",
      "Epoch 3/20\n",
      "188/188 [==============================] - 0s 709us/step - loss: 1.9907 - accuracy: 0.4020 - val_loss: 1.8032 - val_accuracy: 0.4667\n",
      "Epoch 4/20\n",
      "188/188 [==============================] - 0s 741us/step - loss: 1.7467 - accuracy: 0.4718 - val_loss: 1.6465 - val_accuracy: 0.5080\n",
      "Epoch 5/20\n",
      "188/188 [==============================] - 0s 736us/step - loss: 1.6075 - accuracy: 0.5138 - val_loss: 1.5547 - val_accuracy: 0.5333\n",
      "Epoch 6/20\n",
      "188/188 [==============================] - 0s 757us/step - loss: 1.5142 - accuracy: 0.5474 - val_loss: 1.4882 - val_accuracy: 0.5567\n",
      "Epoch 7/20\n",
      "188/188 [==============================] - 0s 704us/step - loss: 1.4443 - accuracy: 0.5718 - val_loss: 1.4218 - val_accuracy: 0.5773\n",
      "Epoch 8/20\n",
      "188/188 [==============================] - 0s 763us/step - loss: 1.3873 - accuracy: 0.5877 - val_loss: 1.3811 - val_accuracy: 0.5827\n",
      "Epoch 9/20\n",
      "188/188 [==============================] - 0s 731us/step - loss: 1.3442 - accuracy: 0.5988 - val_loss: 1.3338 - val_accuracy: 0.6080\n",
      "Epoch 10/20\n",
      "188/188 [==============================] - 0s 720us/step - loss: 1.3009 - accuracy: 0.6168 - val_loss: 1.3043 - val_accuracy: 0.6180\n",
      "Epoch 11/20\n",
      "188/188 [==============================] - 0s 720us/step - loss: 1.2590 - accuracy: 0.6292 - val_loss: 1.2547 - val_accuracy: 0.6340\n",
      "Epoch 12/20\n",
      "188/188 [==============================] - 0s 752us/step - loss: 1.2185 - accuracy: 0.6432 - val_loss: 1.2184 - val_accuracy: 0.6440\n",
      "Epoch 13/20\n",
      "188/188 [==============================] - 0s 731us/step - loss: 1.1814 - accuracy: 0.6542 - val_loss: 1.1886 - val_accuracy: 0.6613\n",
      "Epoch 14/20\n",
      "188/188 [==============================] - 0s 683us/step - loss: 1.1474 - accuracy: 0.6643 - val_loss: 1.1700 - val_accuracy: 0.6607\n",
      "Epoch 15/20\n",
      "188/188 [==============================] - 0s 725us/step - loss: 1.1174 - accuracy: 0.6714 - val_loss: 1.1435 - val_accuracy: 0.6813\n",
      "Epoch 16/20\n",
      "188/188 [==============================] - 0s 677us/step - loss: 1.0887 - accuracy: 0.6858 - val_loss: 1.1217 - val_accuracy: 0.6887\n",
      "Epoch 17/20\n",
      "188/188 [==============================] - 0s 757us/step - loss: 1.0673 - accuracy: 0.6930 - val_loss: 1.0965 - val_accuracy: 0.6907\n",
      "Epoch 18/20\n",
      "188/188 [==============================] - 0s 715us/step - loss: 1.0431 - accuracy: 0.6967 - val_loss: 1.0799 - val_accuracy: 0.6953\n",
      "Epoch 19/20\n",
      "188/188 [==============================] - 0s 757us/step - loss: 1.0246 - accuracy: 0.7015 - val_loss: 1.0804 - val_accuracy: 0.6867\n",
      "Epoch 20/20\n",
      "188/188 [==============================] - 0s 709us/step - loss: 1.0076 - accuracy: 0.7072 - val_loss: 1.0533 - val_accuracy: 0.6973\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x24b23111a90>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mydnn = MyDNN(n_classes= 26)\n",
    "mydnn.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "mydnn.fit(x= X_train, y= y_train, batch_size= 64, epochs= 20, validation_data = (X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:#0b486b\"> 2. Approach 2: Using `tf.keras.Model` Directly</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.keras.layers.Input(shape=(16,)) #declare input layer\n",
    "h = Dense(units=10, activation= 'relu')(X)\n",
    "h = Dense(units=20, activation= 'relu')(h)\n",
    "h = Dense(units=15, activation= 'relu')(h)\n",
    "h = Dense(units=26, activation= 'softmax')(h)\n",
    "dnn_model = tf.keras.Model(inputs= X, outputs=h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "188/188 [==============================] - 0s 1ms/step - loss: 3.1987 - accuracy: 0.0688 - val_loss: 3.0583 - val_accuracy: 0.0853\n",
      "Epoch 2/20\n",
      "188/188 [==============================] - 0s 768us/step - loss: 2.6083 - accuracy: 0.2072 - val_loss: 2.1814 - val_accuracy: 0.3100\n",
      "Epoch 3/20\n",
      "188/188 [==============================] - 0s 741us/step - loss: 1.9828 - accuracy: 0.3913 - val_loss: 1.8144 - val_accuracy: 0.4473\n",
      "Epoch 4/20\n",
      "188/188 [==============================] - 0s 731us/step - loss: 1.7234 - accuracy: 0.4799 - val_loss: 1.6431 - val_accuracy: 0.5127\n",
      "Epoch 5/20\n",
      "188/188 [==============================] - 0s 731us/step - loss: 1.5847 - accuracy: 0.5250 - val_loss: 1.5305 - val_accuracy: 0.5587\n",
      "Epoch 6/20\n",
      "188/188 [==============================] - 0s 757us/step - loss: 1.4864 - accuracy: 0.5635 - val_loss: 1.4480 - val_accuracy: 0.5773\n",
      "Epoch 7/20\n",
      "188/188 [==============================] - 0s 741us/step - loss: 1.4116 - accuracy: 0.5867 - val_loss: 1.3805 - val_accuracy: 0.5967\n",
      "Epoch 8/20\n",
      "188/188 [==============================] - 0s 741us/step - loss: 1.3508 - accuracy: 0.6054 - val_loss: 1.3291 - val_accuracy: 0.6100\n",
      "Epoch 9/20\n",
      "188/188 [==============================] - 0s 741us/step - loss: 1.3000 - accuracy: 0.6267 - val_loss: 1.2840 - val_accuracy: 0.6213\n",
      "Epoch 10/20\n",
      "188/188 [==============================] - 0s 757us/step - loss: 1.2596 - accuracy: 0.6361 - val_loss: 1.2381 - val_accuracy: 0.6413\n",
      "Epoch 11/20\n",
      "188/188 [==============================] - 0s 752us/step - loss: 1.2239 - accuracy: 0.6485 - val_loss: 1.2144 - val_accuracy: 0.6553\n",
      "Epoch 12/20\n",
      "188/188 [==============================] - 0s 747us/step - loss: 1.1947 - accuracy: 0.6567 - val_loss: 1.1848 - val_accuracy: 0.6540\n",
      "Epoch 13/20\n",
      "188/188 [==============================] - 0s 741us/step - loss: 1.1676 - accuracy: 0.6670 - val_loss: 1.1562 - val_accuracy: 0.6793\n",
      "Epoch 14/20\n",
      "188/188 [==============================] - 0s 763us/step - loss: 1.1441 - accuracy: 0.6708 - val_loss: 1.1377 - val_accuracy: 0.6713\n",
      "Epoch 15/20\n",
      "188/188 [==============================] - 0s 747us/step - loss: 1.1218 - accuracy: 0.6794 - val_loss: 1.1216 - val_accuracy: 0.6793\n",
      "Epoch 16/20\n",
      "188/188 [==============================] - 0s 768us/step - loss: 1.1016 - accuracy: 0.6859 - val_loss: 1.0931 - val_accuracy: 0.6900\n",
      "Epoch 17/20\n",
      "188/188 [==============================] - 0s 763us/step - loss: 1.0792 - accuracy: 0.6931 - val_loss: 1.0840 - val_accuracy: 0.6907\n",
      "Epoch 18/20\n",
      "188/188 [==============================] - 0s 725us/step - loss: 1.0604 - accuracy: 0.6971 - val_loss: 1.0831 - val_accuracy: 0.6913\n",
      "Epoch 19/20\n",
      "188/188 [==============================] - 0s 725us/step - loss: 1.0427 - accuracy: 0.7048 - val_loss: 1.0494 - val_accuracy: 0.6993\n",
      "Epoch 20/20\n",
      "188/188 [==============================] - 0s 763us/step - loss: 1.0239 - accuracy: 0.7102 - val_loss: 1.0325 - val_accuracy: 0.7127\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x24b24234d00>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnn_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "dnn_model.fit(x= X_train, y= y_train, batch_size= 64, epochs= 20, validation_data = (X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:#0b486b\"> 3. Approach 3: Using Traditional Mini-batch Approach</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <span style=\"color:#0b486b\">Define a DL model </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnn_model = Sequential()\n",
    "dnn_model.add(Dense(units=10,  input_shape=(16,), activation='relu'))\n",
    "dnn_model.add(Dense(units=20, activation='relu'))\n",
    "dnn_model.add(Dense(units=15, activation='relu'))\n",
    "dnn_model.add(Dense(units=n_classes, activation='softmax'))\n",
    "dnn_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <span style=\"color:#0b486b\">Train model in many epochs</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: train acc=0.2031, train loss=2.8440 | valid acc=0.1973, valid loss= 2.8379\n",
      "Epoch 2: train acc=0.3603, train loss=2.0544 | valid acc=0.3680, valid loss= 2.0491\n",
      "Epoch 3: train acc=0.4647, train loss=1.7685 | valid acc=0.4620, valid loss= 1.7728\n",
      "Epoch 4: train acc=0.5138, train loss=1.6146 | valid acc=0.5133, valid loss= 1.6179\n",
      "Epoch 5: train acc=0.5567, train loss=1.4894 | valid acc=0.5567, valid loss= 1.4892\n",
      "Epoch 6: train acc=0.5961, train loss=1.3852 | valid acc=0.5893, valid loss= 1.3807\n",
      "Epoch 7: train acc=0.6194, train loss=1.3077 | valid acc=0.6187, valid loss= 1.3014\n",
      "Epoch 8: train acc=0.6377, train loss=1.2450 | valid acc=0.6313, valid loss= 1.2390\n",
      "Epoch 9: train acc=0.6504, train loss=1.1955 | valid acc=0.6480, valid loss= 1.1906\n",
      "Epoch 10: train acc=0.6632, train loss=1.1533 | valid acc=0.6647, valid loss= 1.1504\n",
      "Epoch 11: train acc=0.6756, train loss=1.1161 | valid acc=0.6787, valid loss= 1.1157\n",
      "Epoch 12: train acc=0.6873, train loss=1.0830 | valid acc=0.6800, valid loss= 1.0854\n",
      "Epoch 13: train acc=0.6952, train loss=1.0534 | valid acc=0.6867, valid loss= 1.0593\n",
      "Epoch 14: train acc=0.7043, train loss=1.0264 | valid acc=0.6947, valid loss= 1.0357\n",
      "Epoch 15: train acc=0.7105, train loss=1.0019 | valid acc=0.7033, valid loss= 1.0150\n",
      "Epoch 16: train acc=0.7163, train loss=0.9797 | valid acc=0.7140, valid loss= 0.9960\n",
      "Epoch 17: train acc=0.7219, train loss=0.9597 | valid acc=0.7160, valid loss= 0.9789\n",
      "Epoch 18: train acc=0.7272, train loss=0.9422 | valid acc=0.7240, valid loss= 0.9637\n",
      "Epoch 19: train acc=0.7318, train loss=0.9260 | valid acc=0.7260, valid loss= 0.9495\n",
      "Epoch 20: train acc=0.7360, train loss=0.9112 | valid acc=0.7300, valid loss= 0.9376\n"
     ]
    }
   ],
   "source": [
    "n_epochs =20\n",
    "batch_size = 64\n",
    "for epoch in range(n_epochs):\n",
    "    for idx_start in range(0, X_train.shape[0], batch_size):\n",
    "        idx_end = min(X_train.shape[0], idx_start + batch_size)\n",
    "        X_batch, y_batch = X_train[idx_start:idx_end], y_train[idx_start:idx_end]\n",
    "        train_loss_batch = dnn_model.train_on_batch(X_batch, y_batch)  #return the batch loss\n",
    "        \n",
    "    train_loss, train_acc = dnn_model.evaluate(x= X_train, y= y_train, batch_size= 64, verbose= 0)\n",
    "    valid_loss, valid_acc = dnn_model.evaluate(x= X_valid, y= y_valid, batch_size= 64, verbose= 0)\n",
    "    print('Epoch {}: train acc={:.4f}, train loss={:.4f} | valid acc={:.4f}, valid loss= {:.4f}'.format(epoch + 1, train_acc, train_loss, valid_acc, valid_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:#0b486b\"> Additional Exercises </span> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Write your own code to save a trained model to the hard disk and restore this model, then use the restored model to output the prediction result on the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Write code to tune the learning rate in the list [0.1, 0.01, 0.001, 0.005] for Adam."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Insert new code to the above code to enable outputting to TensorBoard the values of `training loss`, `training accuracy`, `valid loss`, and `valid accuracy` at the end of epochs. You can refer to the code [here](https://www.tensorflow.org/tensorboard/get_started)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Write code to do regression on the dataset `cadata` which can be downloaded [here](https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/regression.html). Note that for a regression problem, you need to use the `L2` loss instead of the `cross-entropy` loss as in a classification problem. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:#FFA500\"> Solution for the exercise 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Keras model can be saved and restored via two functions `save()` and `load_model()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ckpt/tf2\\assets\n",
      "Model is saved to: ckpt/tf2\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import models \n",
    "checkpoint_path = \"ckpt/tf2\"\n",
    "\n",
    "dnn_model.save(checkpoint_path)\n",
    "reconstructed_model = models.load_model(checkpoint_path)\n",
    "\n",
    "print(\"Model is saved to: {}\".format(checkpoint_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now can evaluate the reconstructed model on the test sett."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47/47 [==============================] - 0s 689us/step - loss: 0.9864 - accuracy: 0.7200\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9864100813865662, 0.7200000286102295]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reconstructed_model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:#FFA500\"> Solution for the exercise 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to Section II.2.6, we can replace the list of optimizers by a list of learning rates. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*Evaluating with learning rate = 0.1\n",
      "\n",
      "47/47 [==============================] - 0s 544us/step - loss: 2.5355 - accuracy: 0.1420\n",
      "The test accuracy is 0.1420000046491623\n",
      "\n",
      "*Evaluating with learning rate = 0.01\n",
      "\n",
      "47/47 [==============================] - 0s 624us/step - loss: 0.5593 - accuracy: 0.8167\n",
      "The test accuracy is 0.8166666626930237\n",
      "\n",
      "*Evaluating with learning rate = 0.001\n",
      "\n",
      "47/47 [==============================] - 0s 633us/step - loss: 0.8121 - accuracy: 0.7573\n",
      "The test accuracy is 0.7573333382606506\n",
      "\n",
      "*Evaluating with learning rate = 0.005\n",
      "\n",
      "47/47 [==============================] - 0s 512us/step - loss: 0.6455 - accuracy: 0.7920\n",
      "The test accuracy is 0.7919999957084656\n",
      "\n",
      "The best accuracy is 0.8166666626930237 with 0.01\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "learning_rates = [0.1, 0.01, 0.001, 0.005]\n",
    "optimizer_list = [keras.optimizers.Adam(learning_rate=lr) for lr in learning_rates]\n",
    "best_acc = 0\n",
    "best_i = -1\n",
    "for i in range(len(optimizer_list)):\n",
    "    dnn_model.set_weights(model_init)\n",
    "    print(\"*Evaluating with learning rate = {}\\n\".format(str(learning_rates[i])))\n",
    "    dnn_model.compile(optimizer=optimizer_list[i], loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    dnn_model.fit(x=X_train, y=y_train, batch_size=32, epochs=30, validation_data=(X_valid, y_valid), verbose=0)\n",
    "    acc = dnn_model.evaluate(X_test, y_test)[1]\n",
    "    print(\"The test accuracy is {}\\n\".format(acc))\n",
    "    if acc > best_acc:\n",
    "        best_acc = acc\n",
    "        best_i = i\n",
    "print(\"The best accuracy is {} with {}\".format(best_acc, learning_rates[best_i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:#FFA500\"> Solution for the exercise 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, we define a deep learning model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense\n",
    "X = tf.keras.layers.Input(shape=(16,)) # declare input layer\n",
    "h = Dense(units=10, activation= 'relu')(X)\n",
    "h = Dense(units=20, activation= 'relu')(h)\n",
    "h = Dense(units=15, activation= 'relu')(h)\n",
    "h = Dense(units=26, activation= 'softmax')(h)\n",
    "dnn_model = tf.keras.Model(inputs= X, outputs=h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let us combine the defined model with an optimizer, loss, and metrics.\n",
    "Adding a `tf.keras.callbacks.TensorBoard` callback will enable outputting the values of `training loss`, `training accuracy`, `valid loss`, and `valid accuracy` at the end of epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.9862 - accuracy: 0.1168 - val_loss: 2.3230 - val_accuracy: 0.2913\n",
      "Epoch 2/100\n",
      "375/375 [==============================] - 0s 691us/step - loss: 1.8472 - accuracy: 0.4440 - val_loss: 1.5941 - val_accuracy: 0.5400\n",
      "Epoch 3/100\n",
      "375/375 [==============================] - 0s 686us/step - loss: 1.4707 - accuracy: 0.5722 - val_loss: 1.3960 - val_accuracy: 0.5980\n",
      "Epoch 4/100\n",
      "375/375 [==============================] - 0s 671us/step - loss: 1.3151 - accuracy: 0.6125 - val_loss: 1.2630 - val_accuracy: 0.6373\n",
      "Epoch 5/100\n",
      "375/375 [==============================] - 0s 688us/step - loss: 1.2262 - accuracy: 0.6387 - val_loss: 1.1913 - val_accuracy: 0.6573\n",
      "Epoch 6/100\n",
      "375/375 [==============================] - 0s 683us/step - loss: 1.1632 - accuracy: 0.6650 - val_loss: 1.1486 - val_accuracy: 0.6793\n",
      "Epoch 7/100\n",
      "375/375 [==============================] - 0s 683us/step - loss: 1.1128 - accuracy: 0.6813 - val_loss: 1.1014 - val_accuracy: 0.6940\n",
      "Epoch 8/100\n",
      "375/375 [==============================] - 0s 677us/step - loss: 1.0722 - accuracy: 0.6920 - val_loss: 1.0595 - val_accuracy: 0.7053\n",
      "Epoch 9/100\n",
      "375/375 [==============================] - 0s 675us/step - loss: 1.0378 - accuracy: 0.6995 - val_loss: 1.0357 - val_accuracy: 0.7073\n",
      "Epoch 10/100\n",
      "375/375 [==============================] - 0s 680us/step - loss: 1.0065 - accuracy: 0.7080 - val_loss: 0.9987 - val_accuracy: 0.7233\n",
      "Epoch 11/100\n",
      "375/375 [==============================] - 0s 693us/step - loss: 0.9778 - accuracy: 0.7151 - val_loss: 0.9872 - val_accuracy: 0.7200\n",
      "Epoch 12/100\n",
      "375/375 [==============================] - 0s 681us/step - loss: 0.9541 - accuracy: 0.7213 - val_loss: 0.9559 - val_accuracy: 0.7247\n",
      "Epoch 13/100\n",
      "375/375 [==============================] - 0s 673us/step - loss: 0.9333 - accuracy: 0.7285 - val_loss: 0.9471 - val_accuracy: 0.7180\n",
      "Epoch 14/100\n",
      "375/375 [==============================] - 0s 690us/step - loss: 0.9160 - accuracy: 0.7297 - val_loss: 0.9425 - val_accuracy: 0.7287\n",
      "Epoch 15/100\n",
      "375/375 [==============================] - 0s 677us/step - loss: 0.8987 - accuracy: 0.7333 - val_loss: 0.9012 - val_accuracy: 0.7433\n",
      "Epoch 16/100\n",
      "375/375 [==============================] - 0s 696us/step - loss: 0.8816 - accuracy: 0.7389 - val_loss: 0.8976 - val_accuracy: 0.7373\n",
      "Epoch 17/100\n",
      "375/375 [==============================] - 0s 693us/step - loss: 0.8680 - accuracy: 0.7413 - val_loss: 0.8829 - val_accuracy: 0.7460\n",
      "Epoch 18/100\n",
      "375/375 [==============================] - 0s 688us/step - loss: 0.8533 - accuracy: 0.7473 - val_loss: 0.8714 - val_accuracy: 0.7480\n",
      "Epoch 19/100\n",
      "375/375 [==============================] - 0s 680us/step - loss: 0.8423 - accuracy: 0.7497 - val_loss: 0.8495 - val_accuracy: 0.7540\n",
      "Epoch 20/100\n",
      "375/375 [==============================] - 0s 680us/step - loss: 0.8285 - accuracy: 0.7536 - val_loss: 0.8412 - val_accuracy: 0.7573\n",
      "Epoch 21/100\n",
      "375/375 [==============================] - 0s 685us/step - loss: 0.8176 - accuracy: 0.7574 - val_loss: 0.8358 - val_accuracy: 0.7567\n",
      "Epoch 22/100\n",
      "375/375 [==============================] - 0s 675us/step - loss: 0.8067 - accuracy: 0.7607 - val_loss: 0.8290 - val_accuracy: 0.7587\n",
      "Epoch 23/100\n",
      "375/375 [==============================] - 0s 683us/step - loss: 0.7952 - accuracy: 0.7601 - val_loss: 0.8160 - val_accuracy: 0.7647\n",
      "Epoch 24/100\n",
      "375/375 [==============================] - 0s 680us/step - loss: 0.7854 - accuracy: 0.7663 - val_loss: 0.8111 - val_accuracy: 0.7620\n",
      "Epoch 25/100\n",
      "375/375 [==============================] - 0s 696us/step - loss: 0.7781 - accuracy: 0.7680 - val_loss: 0.7913 - val_accuracy: 0.7673\n",
      "Epoch 26/100\n",
      "375/375 [==============================] - 0s 685us/step - loss: 0.7663 - accuracy: 0.7687 - val_loss: 0.7873 - val_accuracy: 0.7707\n",
      "Epoch 27/100\n",
      "375/375 [==============================] - 0s 691us/step - loss: 0.7587 - accuracy: 0.7692 - val_loss: 0.7776 - val_accuracy: 0.7727\n",
      "Epoch 28/100\n",
      "375/375 [==============================] - 0s 683us/step - loss: 0.7507 - accuracy: 0.7701 - val_loss: 0.7816 - val_accuracy: 0.7667\n",
      "Epoch 29/100\n",
      "375/375 [==============================] - 0s 685us/step - loss: 0.7419 - accuracy: 0.7734 - val_loss: 0.7643 - val_accuracy: 0.7767\n",
      "Epoch 30/100\n",
      "375/375 [==============================] - 0s 685us/step - loss: 0.7368 - accuracy: 0.7766 - val_loss: 0.7555 - val_accuracy: 0.7760\n",
      "Epoch 31/100\n",
      "375/375 [==============================] - 0s 699us/step - loss: 0.7273 - accuracy: 0.7763 - val_loss: 0.7481 - val_accuracy: 0.7793\n",
      "Epoch 32/100\n",
      "375/375 [==============================] - 0s 680us/step - loss: 0.7203 - accuracy: 0.7816 - val_loss: 0.7457 - val_accuracy: 0.7800\n",
      "Epoch 33/100\n",
      "375/375 [==============================] - 0s 691us/step - loss: 0.7142 - accuracy: 0.7828 - val_loss: 0.7494 - val_accuracy: 0.7740\n",
      "Epoch 34/100\n",
      "375/375 [==============================] - 0s 693us/step - loss: 0.7087 - accuracy: 0.7828 - val_loss: 0.7335 - val_accuracy: 0.7767\n",
      "Epoch 35/100\n",
      "375/375 [==============================] - 0s 691us/step - loss: 0.7005 - accuracy: 0.7862 - val_loss: 0.7268 - val_accuracy: 0.7813\n",
      "Epoch 36/100\n",
      "375/375 [==============================] - 0s 725us/step - loss: 0.6954 - accuracy: 0.7883 - val_loss: 0.7184 - val_accuracy: 0.7887\n",
      "Epoch 37/100\n",
      "375/375 [==============================] - 0s 685us/step - loss: 0.6917 - accuracy: 0.7874 - val_loss: 0.7315 - val_accuracy: 0.7867\n",
      "Epoch 38/100\n",
      "375/375 [==============================] - 0s 696us/step - loss: 0.6850 - accuracy: 0.7884 - val_loss: 0.7187 - val_accuracy: 0.7853\n",
      "Epoch 39/100\n",
      "375/375 [==============================] - 0s 683us/step - loss: 0.6801 - accuracy: 0.7897 - val_loss: 0.7219 - val_accuracy: 0.7800\n",
      "Epoch 40/100\n",
      "375/375 [==============================] - 0s 683us/step - loss: 0.6747 - accuracy: 0.7895 - val_loss: 0.7091 - val_accuracy: 0.7887\n",
      "Epoch 41/100\n",
      "375/375 [==============================] - 0s 693us/step - loss: 0.6692 - accuracy: 0.7943 - val_loss: 0.7146 - val_accuracy: 0.7940\n",
      "Epoch 42/100\n",
      "375/375 [==============================] - 0s 699us/step - loss: 0.6651 - accuracy: 0.7962 - val_loss: 0.6943 - val_accuracy: 0.7967\n",
      "Epoch 43/100\n",
      "375/375 [==============================] - 0s 712us/step - loss: 0.6607 - accuracy: 0.7954 - val_loss: 0.6905 - val_accuracy: 0.8027\n",
      "Epoch 44/100\n",
      "375/375 [==============================] - 0s 680us/step - loss: 0.6556 - accuracy: 0.8001 - val_loss: 0.6813 - val_accuracy: 0.8013\n",
      "Epoch 45/100\n",
      "375/375 [==============================] - 0s 693us/step - loss: 0.6523 - accuracy: 0.8000 - val_loss: 0.6876 - val_accuracy: 0.7960\n",
      "Epoch 46/100\n",
      "375/375 [==============================] - 0s 688us/step - loss: 0.6466 - accuracy: 0.8006 - val_loss: 0.6964 - val_accuracy: 0.7973\n",
      "Epoch 47/100\n",
      "375/375 [==============================] - 0s 683us/step - loss: 0.6407 - accuracy: 0.8027 - val_loss: 0.6712 - val_accuracy: 0.7973\n",
      "Epoch 48/100\n",
      "375/375 [==============================] - 0s 680us/step - loss: 0.6379 - accuracy: 0.8040 - val_loss: 0.6760 - val_accuracy: 0.8007\n",
      "Epoch 49/100\n",
      "375/375 [==============================] - 0s 693us/step - loss: 0.6343 - accuracy: 0.8043 - val_loss: 0.6740 - val_accuracy: 0.8027\n",
      "Epoch 50/100\n",
      "375/375 [==============================] - 0s 685us/step - loss: 0.6305 - accuracy: 0.8043 - val_loss: 0.6616 - val_accuracy: 0.8080\n",
      "Epoch 51/100\n",
      "375/375 [==============================] - 0s 683us/step - loss: 0.6261 - accuracy: 0.8072 - val_loss: 0.6632 - val_accuracy: 0.8020\n",
      "Epoch 52/100\n",
      "375/375 [==============================] - 0s 688us/step - loss: 0.6225 - accuracy: 0.8082 - val_loss: 0.6616 - val_accuracy: 0.8067\n",
      "Epoch 53/100\n",
      "375/375 [==============================] - 0s 688us/step - loss: 0.6210 - accuracy: 0.8088 - val_loss: 0.6595 - val_accuracy: 0.8087\n",
      "Epoch 54/100\n",
      "375/375 [==============================] - 0s 725us/step - loss: 0.6165 - accuracy: 0.8091 - val_loss: 0.6534 - val_accuracy: 0.8007\n",
      "Epoch 55/100\n",
      "375/375 [==============================] - 0s 691us/step - loss: 0.6116 - accuracy: 0.8096 - val_loss: 0.6436 - val_accuracy: 0.8120\n",
      "Epoch 56/100\n",
      "375/375 [==============================] - 0s 683us/step - loss: 0.6088 - accuracy: 0.8102 - val_loss: 0.6449 - val_accuracy: 0.8053\n",
      "Epoch 57/100\n",
      "375/375 [==============================] - 0s 683us/step - loss: 0.6061 - accuracy: 0.8092 - val_loss: 0.6459 - val_accuracy: 0.8100\n",
      "Epoch 58/100\n",
      "375/375 [==============================] - 0s 667us/step - loss: 0.6002 - accuracy: 0.8127 - val_loss: 0.6400 - val_accuracy: 0.8113\n",
      "Epoch 59/100\n",
      "375/375 [==============================] - 0s 677us/step - loss: 0.5976 - accuracy: 0.8137 - val_loss: 0.6414 - val_accuracy: 0.8040\n",
      "Epoch 60/100\n",
      "375/375 [==============================] - 0s 680us/step - loss: 0.5982 - accuracy: 0.8142 - val_loss: 0.6414 - val_accuracy: 0.8087\n",
      "Epoch 61/100\n",
      "375/375 [==============================] - 0s 680us/step - loss: 0.5917 - accuracy: 0.8163 - val_loss: 0.6308 - val_accuracy: 0.8107\n",
      "Epoch 62/100\n",
      "375/375 [==============================] - 0s 701us/step - loss: 0.5908 - accuracy: 0.8153 - val_loss: 0.6336 - val_accuracy: 0.8080\n",
      "Epoch 63/100\n",
      "375/375 [==============================] - 0s 704us/step - loss: 0.5873 - accuracy: 0.8191 - val_loss: 0.6261 - val_accuracy: 0.8127\n",
      "Epoch 64/100\n",
      "375/375 [==============================] - 0s 659us/step - loss: 0.5836 - accuracy: 0.8157 - val_loss: 0.6195 - val_accuracy: 0.8133\n",
      "Epoch 65/100\n",
      "375/375 [==============================] - 0s 683us/step - loss: 0.5801 - accuracy: 0.8188 - val_loss: 0.6297 - val_accuracy: 0.8073\n",
      "Epoch 66/100\n",
      "375/375 [==============================] - 0s 715us/step - loss: 0.5763 - accuracy: 0.8223 - val_loss: 0.6216 - val_accuracy: 0.8093\n",
      "Epoch 67/100\n",
      "375/375 [==============================] - 0s 691us/step - loss: 0.5740 - accuracy: 0.8227 - val_loss: 0.6233 - val_accuracy: 0.8080\n",
      "Epoch 68/100\n",
      "375/375 [==============================] - 0s 616us/step - loss: 0.5713 - accuracy: 0.8222 - val_loss: 0.6178 - val_accuracy: 0.8207\n",
      "Epoch 69/100\n",
      "375/375 [==============================] - 0s 704us/step - loss: 0.5720 - accuracy: 0.8227 - val_loss: 0.6186 - val_accuracy: 0.8180\n",
      "Epoch 70/100\n",
      "375/375 [==============================] - 0s 696us/step - loss: 0.5661 - accuracy: 0.8232 - val_loss: 0.6105 - val_accuracy: 0.8200\n",
      "Epoch 71/100\n",
      "375/375 [==============================] - 0s 688us/step - loss: 0.5649 - accuracy: 0.8229 - val_loss: 0.6068 - val_accuracy: 0.8120\n",
      "Epoch 72/100\n",
      "375/375 [==============================] - 0s 685us/step - loss: 0.5609 - accuracy: 0.8248 - val_loss: 0.6070 - val_accuracy: 0.8173\n",
      "Epoch 73/100\n",
      "375/375 [==============================] - 0s 693us/step - loss: 0.5602 - accuracy: 0.8259 - val_loss: 0.6138 - val_accuracy: 0.8113\n",
      "Epoch 74/100\n",
      "375/375 [==============================] - 0s 683us/step - loss: 0.5570 - accuracy: 0.8268 - val_loss: 0.6159 - val_accuracy: 0.8087\n",
      "Epoch 75/100\n",
      "375/375 [==============================] - 0s 691us/step - loss: 0.5543 - accuracy: 0.8273 - val_loss: 0.6117 - val_accuracy: 0.8187\n",
      "Epoch 76/100\n",
      "375/375 [==============================] - 0s 685us/step - loss: 0.5532 - accuracy: 0.8283 - val_loss: 0.6087 - val_accuracy: 0.8200\n",
      "Epoch 77/100\n",
      "375/375 [==============================] - 0s 685us/step - loss: 0.5531 - accuracy: 0.8299 - val_loss: 0.5976 - val_accuracy: 0.8200\n",
      "Epoch 78/100\n",
      "375/375 [==============================] - 0s 685us/step - loss: 0.5479 - accuracy: 0.8282 - val_loss: 0.6000 - val_accuracy: 0.8180\n",
      "Epoch 79/100\n",
      "375/375 [==============================] - 0s 699us/step - loss: 0.5469 - accuracy: 0.8287 - val_loss: 0.6035 - val_accuracy: 0.8133\n",
      "Epoch 80/100\n",
      "375/375 [==============================] - 0s 688us/step - loss: 0.5458 - accuracy: 0.8327 - val_loss: 0.6065 - val_accuracy: 0.8120\n",
      "Epoch 81/100\n",
      "375/375 [==============================] - 0s 704us/step - loss: 0.5451 - accuracy: 0.8294 - val_loss: 0.6005 - val_accuracy: 0.8220\n",
      "Epoch 82/100\n",
      "375/375 [==============================] - 0s 715us/step - loss: 0.5418 - accuracy: 0.8320 - val_loss: 0.6043 - val_accuracy: 0.8207\n",
      "Epoch 83/100\n",
      "375/375 [==============================] - 0s 691us/step - loss: 0.5392 - accuracy: 0.8317 - val_loss: 0.6140 - val_accuracy: 0.8093\n",
      "Epoch 84/100\n",
      "375/375 [==============================] - 0s 713us/step - loss: 0.5398 - accuracy: 0.8316 - val_loss: 0.5950 - val_accuracy: 0.8207\n",
      "Epoch 85/100\n",
      "375/375 [==============================] - 0s 700us/step - loss: 0.5385 - accuracy: 0.8294 - val_loss: 0.5947 - val_accuracy: 0.8233\n",
      "Epoch 86/100\n",
      "375/375 [==============================] - 0s 743us/step - loss: 0.5332 - accuracy: 0.8327 - val_loss: 0.5981 - val_accuracy: 0.8200\n",
      "Epoch 87/100\n",
      "375/375 [==============================] - 0s 693us/step - loss: 0.5339 - accuracy: 0.8351 - val_loss: 0.6049 - val_accuracy: 0.8187\n",
      "Epoch 88/100\n",
      "375/375 [==============================] - 0s 692us/step - loss: 0.5302 - accuracy: 0.8331 - val_loss: 0.5930 - val_accuracy: 0.8213\n",
      "Epoch 89/100\n",
      "375/375 [==============================] - 0s 686us/step - loss: 0.5269 - accuracy: 0.8354 - val_loss: 0.5790 - val_accuracy: 0.8273\n",
      "Epoch 90/100\n",
      "375/375 [==============================] - 0s 688us/step - loss: 0.5294 - accuracy: 0.8339 - val_loss: 0.5855 - val_accuracy: 0.8233\n",
      "Epoch 91/100\n",
      "375/375 [==============================] - 0s 738us/step - loss: 0.5255 - accuracy: 0.8361 - val_loss: 0.5878 - val_accuracy: 0.8233\n",
      "Epoch 92/100\n",
      "375/375 [==============================] - 0s 683us/step - loss: 0.5274 - accuracy: 0.8350 - val_loss: 0.5839 - val_accuracy: 0.8180\n",
      "Epoch 93/100\n",
      "375/375 [==============================] - 0s 688us/step - loss: 0.5225 - accuracy: 0.8365 - val_loss: 0.6119 - val_accuracy: 0.8127\n",
      "Epoch 94/100\n",
      "375/375 [==============================] - 0s 691us/step - loss: 0.5229 - accuracy: 0.8367 - val_loss: 0.5874 - val_accuracy: 0.8233\n",
      "Epoch 95/100\n",
      "375/375 [==============================] - 0s 691us/step - loss: 0.5203 - accuracy: 0.8361 - val_loss: 0.5763 - val_accuracy: 0.8273\n",
      "Epoch 96/100\n",
      "375/375 [==============================] - 0s 695us/step - loss: 0.5195 - accuracy: 0.8358 - val_loss: 0.5741 - val_accuracy: 0.8267\n",
      "Epoch 97/100\n",
      "375/375 [==============================] - 0s 693us/step - loss: 0.5167 - accuracy: 0.8411 - val_loss: 0.5663 - val_accuracy: 0.8273\n",
      "Epoch 98/100\n",
      "375/375 [==============================] - 0s 676us/step - loss: 0.5153 - accuracy: 0.8401 - val_loss: 0.5783 - val_accuracy: 0.8213\n",
      "Epoch 99/100\n",
      "375/375 [==============================] - 0s 680us/step - loss: 0.5131 - accuracy: 0.8403 - val_loss: 0.5752 - val_accuracy: 0.8273\n",
      "Epoch 100/100\n",
      "375/375 [==============================] - 0s 689us/step - loss: 0.5137 - accuracy: 0.8391 - val_loss: 0.5734 - val_accuracy: 0.8227\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x24b27a1feb0>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime\n",
    "dnn_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "log_dir = \"logs/tf2/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")  # declare the directory to save logs.\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "dnn_model.fit(x=X_train, y=y_train, batch_size=32, epochs=100, validation_data=(X_valid, y_valid), callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Open command line, nevigate to the folder of this tute and run **> tensorboard --logdir \"logs/tf2\"**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:#FFA500\"> Solution for the exercise 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X data shape: (20640, 8)\n",
      "y data shape: (20640, 1)\n",
      "x-min=-124.35, x-max=39320.0\n",
      "We need to scale the features of this data into [-1,1]\n"
     ]
    }
   ],
   "source": [
    "# We load and process the dataset\n",
    "data_file_name= \"cadata.libsvm\"\n",
    "data_file = os.path.abspath(\"./data/\" + data_file_name)\n",
    "X_data, y_data = load_svmlight_file(data_file)\n",
    "X_data= X_data.toarray()\n",
    "y_data= y_data.reshape(y_data.shape[0],-1)\n",
    "print(\"X data shape: {}\".format(X_data.shape))\n",
    "print(\"y data shape: {}\".format(y_data.shape))\n",
    "print(\"x-min={}, x-max={}\".format(np.min(X_data), np.max(X_data)))\n",
    "print(\"We need to scale the features of this data into [-1,1]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x-min=-1.0, x-max=1.0\n"
     ]
    }
   ],
   "source": [
    "# We scale the features of this data into [-1,1]\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "X_data= MinMaxScaler(feature_range= (-1,1)).fit_transform(X_data)\n",
    "print(\"x-min={}, x-max={}\".format(np.min(X_data), np.max(X_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before scaling: y-min =14999.0, y-max =500001.0\n",
      "After scaling: y-min =-0.9999999999999999, y-max =1.0\n",
      "Next step is to split the dataset into train (80%), valid (10%), and test (10%)\n"
     ]
    }
   ],
   "source": [
    "print(\"Before scaling: y-min ={}, y-max ={}\".format(np.min(y_data), np.max(y_data)))\n",
    "y_data= MinMaxScaler(feature_range= (-1,1)).fit_transform(y_data)\n",
    "print(\"After scaling: y-min ={}, y-max ={}\".format(np.min(y_data), np.max(y_data)))\n",
    "print(\"Next step is to split the dataset into train (80%), valid (10%), and test (10%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16512, 8) (2064, 8) (2064, 8)\n",
      "(16512,) (2064,) (2064,)\n",
      "Three sets are ready! Next step is to build up a deep neural network.\n"
     ]
    }
   ],
   "source": [
    "# We split train, valid and test data\n",
    "X_train, X_valid, X_test, y_train, y_valid, y_test = train_valid_test_split(X_data, y_data, train_size=0.8, test_size=0.1)\n",
    "y_train= y_train.reshape(-1)\n",
    "y_test= y_test.reshape(-1)\n",
    "y_valid= y_valid.reshape(-1)\n",
    "print(X_train.shape, X_valid.shape, X_test.shape)\n",
    "print(y_train.shape, y_valid.shape, y_test.shape)\n",
    "print(\"Three sets are ready! Next step is to build up a deep neural network.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "regression_model = Sequential()\n",
    "regression_model.add(Dense(units=1)) # output has only one neuron\n",
    "regression_model.compile(optimizer=tf.optimizers.Adam(learning_rate=0.0001), loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "516/516 [==============================] - 0s 503us/step - loss: 1.1897 - val_loss: 0.9961\n",
      "Epoch 2/50\n",
      "516/516 [==============================] - 0s 399us/step - loss: 0.8215 - val_loss: 0.7060\n",
      "Epoch 3/50\n",
      "516/516 [==============================] - 0s 391us/step - loss: 0.5978 - val_loss: 0.5356\n",
      "Epoch 4/50\n",
      "516/516 [==============================] - 0s 392us/step - loss: 0.4707 - val_loss: 0.4409\n",
      "Epoch 5/50\n",
      "516/516 [==============================] - 0s 395us/step - loss: 0.4016 - val_loss: 0.3885\n",
      "Epoch 6/50\n",
      "516/516 [==============================] - 0s 392us/step - loss: 0.3617 - val_loss: 0.3550\n",
      "Epoch 7/50\n",
      "516/516 [==============================] - 0s 395us/step - loss: 0.3342 - val_loss: 0.3292\n",
      "Epoch 8/50\n",
      "516/516 [==============================] - 0s 383us/step - loss: 0.3118 - val_loss: 0.3070\n",
      "Epoch 9/50\n",
      "516/516 [==============================] - 0s 383us/step - loss: 0.2923 - val_loss: 0.2875\n",
      "Epoch 10/50\n",
      "516/516 [==============================] - 0s 386us/step - loss: 0.2753 - val_loss: 0.2705\n",
      "Epoch 11/50\n",
      "516/516 [==============================] - 0s 407us/step - loss: 0.2602 - val_loss: 0.2556\n",
      "Epoch 12/50\n",
      "516/516 [==============================] - 0s 382us/step - loss: 0.2470 - val_loss: 0.2423\n",
      "Epoch 13/50\n",
      "516/516 [==============================] - 0s 399us/step - loss: 0.2352 - val_loss: 0.2304\n",
      "Epoch 14/50\n",
      "516/516 [==============================] - 0s 395us/step - loss: 0.2245 - val_loss: 0.2197\n",
      "Epoch 15/50\n",
      "516/516 [==============================] - 0s 391us/step - loss: 0.2147 - val_loss: 0.2099\n",
      "Epoch 16/50\n",
      "516/516 [==============================] - 0s 381us/step - loss: 0.2056 - val_loss: 0.2009\n",
      "Epoch 17/50\n",
      "516/516 [==============================] - 0s 386us/step - loss: 0.1971 - val_loss: 0.1923\n",
      "Epoch 18/50\n",
      "516/516 [==============================] - 0s 392us/step - loss: 0.1891 - val_loss: 0.1843\n",
      "Epoch 19/50\n",
      "516/516 [==============================] - 0s 396us/step - loss: 0.1815 - val_loss: 0.1768\n",
      "Epoch 20/50\n",
      "516/516 [==============================] - 0s 381us/step - loss: 0.1744 - val_loss: 0.1698\n",
      "Epoch 21/50\n",
      "516/516 [==============================] - 0s 388us/step - loss: 0.1677 - val_loss: 0.1631\n",
      "Epoch 22/50\n",
      "516/516 [==============================] - 0s 386us/step - loss: 0.1613 - val_loss: 0.1570\n",
      "Epoch 23/50\n",
      "516/516 [==============================] - 0s 406us/step - loss: 0.1553 - val_loss: 0.1510\n",
      "Epoch 24/50\n",
      "516/516 [==============================] - 0s 386us/step - loss: 0.1497 - val_loss: 0.1456\n",
      "Epoch 25/50\n",
      "516/516 [==============================] - 0s 390us/step - loss: 0.1444 - val_loss: 0.1404\n",
      "Epoch 26/50\n",
      "516/516 [==============================] - 0s 420us/step - loss: 0.1394 - val_loss: 0.1355\n",
      "Epoch 27/50\n",
      "516/516 [==============================] - 0s 412us/step - loss: 0.1347 - val_loss: 0.1311\n",
      "Epoch 28/50\n",
      "516/516 [==============================] - 0s 402us/step - loss: 0.1304 - val_loss: 0.1269\n",
      "Epoch 29/50\n",
      "516/516 [==============================] - 0s 396us/step - loss: 0.1263 - val_loss: 0.1231\n",
      "Epoch 30/50\n",
      "516/516 [==============================] - 0s 395us/step - loss: 0.1226 - val_loss: 0.1196\n",
      "Epoch 31/50\n",
      "516/516 [==============================] - 0s 393us/step - loss: 0.1191 - val_loss: 0.1163\n",
      "Epoch 32/50\n",
      "516/516 [==============================] - 0s 378us/step - loss: 0.1160 - val_loss: 0.1134\n",
      "Epoch 33/50\n",
      "516/516 [==============================] - 0s 400us/step - loss: 0.1131 - val_loss: 0.1107\n",
      "Epoch 34/50\n",
      "516/516 [==============================] - 0s 404us/step - loss: 0.1104 - val_loss: 0.1084\n",
      "Epoch 35/50\n",
      "516/516 [==============================] - 0s 385us/step - loss: 0.1081 - val_loss: 0.1062\n",
      "Epoch 36/50\n",
      "516/516 [==============================] - 0s 389us/step - loss: 0.1059 - val_loss: 0.1043\n",
      "Epoch 37/50\n",
      "516/516 [==============================] - 0s 394us/step - loss: 0.1040 - val_loss: 0.1027\n",
      "Epoch 38/50\n",
      "516/516 [==============================] - 0s 383us/step - loss: 0.1023 - val_loss: 0.1012\n",
      "Epoch 39/50\n",
      "516/516 [==============================] - 0s 380us/step - loss: 0.1009 - val_loss: 0.1000\n",
      "Epoch 40/50\n",
      "516/516 [==============================] - 0s 387us/step - loss: 0.0996 - val_loss: 0.0990\n",
      "Epoch 41/50\n",
      "516/516 [==============================] - 0s 388us/step - loss: 0.0984 - val_loss: 0.0980\n",
      "Epoch 42/50\n",
      "516/516 [==============================] - 0s 389us/step - loss: 0.0974 - val_loss: 0.0972\n",
      "Epoch 43/50\n",
      "516/516 [==============================] - 0s 376us/step - loss: 0.0966 - val_loss: 0.0965\n",
      "Epoch 44/50\n",
      "516/516 [==============================] - 0s 381us/step - loss: 0.0958 - val_loss: 0.0959\n",
      "Epoch 45/50\n",
      "516/516 [==============================] - 0s 408us/step - loss: 0.0952 - val_loss: 0.0955\n",
      "Epoch 46/50\n",
      "516/516 [==============================] - 0s 389us/step - loss: 0.0946 - val_loss: 0.0951\n",
      "Epoch 47/50\n",
      "516/516 [==============================] - 0s 393us/step - loss: 0.0942 - val_loss: 0.0948\n",
      "Epoch 48/50\n",
      "516/516 [==============================] - 0s 401us/step - loss: 0.0938 - val_loss: 0.0945\n",
      "Epoch 49/50\n",
      "516/516 [==============================] - 0s 403us/step - loss: 0.0935 - val_loss: 0.0943\n",
      "Epoch 50/50\n",
      "516/516 [==============================] - 0s 390us/step - loss: 0.0932 - val_loss: 0.0941\n"
     ]
    }
   ],
   "source": [
    "history = regression_model.fit(x= X_train, y= y_train, batch_size= 32, epochs= 50, validation_data = (X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot losses during training\n",
    "from matplotlib import pyplot\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.plot(history.history['val_loss'], label='validation')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now can evaluate our regression model on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65/65 [==============================] - 0s 372us/step - loss: 0.0942\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0941537469625473"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regression_model.evaluate(X_test, y_test) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### <span style=\"color:#0b486b\"> <div  style=\"text-align:center\">**THE END**</div> </span>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2.5",
   "language": "python",
   "name": "tf2.5"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
